[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Omotola Ayodele Lawal",
    "section": "",
    "text": "I am a dedicated and detail-oriented medical doctor with a strong focus on clinical care and patient-centered solutions. I excel in collaborative environments, adapt quickly to challenging circumstances, and take the initiative to drive results. Beyond my medical practice, I am passionate about leveraging data science to uncover insights and solve complex problems. I also enjoy mentoring high school graduates, helping them make informed decisions about their career paths."
  },
  {
    "objectID": "docs/posts/post-with-code/index.html",
    "href": "docs/posts/post-with-code/index.html",
    "title": "Conditional Mutation",
    "section": "",
    "text": "This was a quiz on the topic: Conditional Mutation. You can find the project here"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Conditional Mutation",
    "section": "",
    "text": "This was a quiz on the topic: Conditional Mutation. You can find the project here"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Investigating the Netflix Movies",
    "section": "",
    "text": "This is the second project published in my portfolio. You can find it here"
  },
  {
    "objectID": "Portfolio.html",
    "href": "Portfolio.html",
    "title": "Lawal’s Portfolio",
    "section": "",
    "text": "PROJECT | BUILDING A CALORIE INTAKE CALCULATOR\n\n\n\n\n\n\nProject\n\n\n\n\n\n\n\n\n\nNov 30, 2024\n\n\nOmotola Ayodele Lawal\n\n\n\n\n\n\n\n\n\n\n\n\nPROJECT | MODELING CAR INSURANCE CLAIMS OUTCOME\n\n\n\n\n\n\nProject\n\n\n\n\n\n\n\n\n\nNov 23, 2024\n\n\nOmotola Ayodele Lawal\n\n\n\n\n\n\n\n\n\n\n\n\nPROJECT | EXPLORING AIRBNB MARKET TRENDS\n\n\n\n\n\n\nProject\n\n\n\n\n\n\n\n\n\nOct 23, 2024\n\n\nOmotola Ayodele Lawal\n\n\n\n\n\n\n\n\n\n\n\n\nCUSTOMER ANALYTICS: PREPARING DATA FOR MODELLING\n\n\n\n\n\n\nProject\n\n\n\n\n\n\n\n\n\nSep 16, 2024\n\n\nOmotola Ayodele Lawal\n\n\n\n\n\n\n\n\n\n\n\n\nGAPMINDER | LIFE EXPECTANCIES 2007\n\n\n\n\n\n\ndashboard\n\n\ndata\n\n\ninformation\n\n\n\n\n\n\n\n\n\nSep 7, 2024\n\n\nOmotola Ayodele Lawal\n\n\n\n\n\n\n\n\n\n\n\n\nInvestigating the Netflix Movies\n\n\n\n\n\n\nProject\n\n\n\n\n\n\n\n\n\nSep 1, 2024\n\n\nLawal Omotola\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Joining_data_with_pandas/index.html",
    "href": "posts/Joining_data_with_pandas/index.html",
    "title": "Joining data with Pandas",
    "section": "",
    "text": "The pandas package is a powerful tool for manipulating and transforming data in python. However, when working on an analytics, the data needed could be in multiple tables. Check here for some illustrations."
  },
  {
    "objectID": "posts/first_dashboard/main_dash.html",
    "href": "posts/first_dashboard/main_dash.html",
    "title": "GAPMINDER | LIFE EXPECTANCIES 2007",
    "section": "",
    "text": "This dashboard summarize and visualize the life expectancy of countries for the year 2007.\nClick here for more details."
  },
  {
    "objectID": "cert/MDCN/mdcn.html",
    "href": "cert/MDCN/mdcn.html",
    "title": "Omotola Ayodele Lawal",
    "section": "",
    "text": "{{&lt; pdf ANNUAL PRACTICING LICENCE (2024).pdf 600 400 &gt;}}"
  },
  {
    "objectID": "cert/OpenWHO/index.html",
    "href": "cert/OpenWHO/index.html",
    "title": "Joining data with Pandas",
    "section": "",
    "text": "The pandas package is a powerful tool for manipulating and transforming data in python. However, when working on an analytics, the data needed could be in multiple tables. Check here for some illustrations."
  },
  {
    "objectID": "cert/DataCamp/index.html",
    "href": "cert/DataCamp/index.html",
    "title": "Joining data with Pandas",
    "section": "",
    "text": "The pandas package is a powerful tool for manipulating and transforming data in python. However, when working on an analytics, the data needed could be in multiple tables. Check here for some illustrations."
  },
  {
    "objectID": "Cert.html",
    "href": "Cert.html",
    "title": "Certification",
    "section": "",
    "text": "No matching items",
    "crumbs": [
      "Certification"
    ]
  },
  {
    "objectID": "annual.html",
    "href": "annual.html",
    "title": "ANNUAL PRACTICING LICENSE",
    "section": "",
    "text": "This is my Annual Practicing License for the year 2024.",
    "crumbs": [
      "Certification",
      "ANNUAL PRACTICING LICENSE"
    ]
  },
  {
    "objectID": "reg.html",
    "href": "reg.html",
    "title": "CERTIFICATE OF FULL REGISTRATION",
    "section": "",
    "text": "This is my Certificate of Full Registration.",
    "crumbs": [
      "Certification",
      "CERTIFICATE OF FULL REGISTRATION"
    ]
  },
  {
    "objectID": "posts/post-with-code/conditional.html",
    "href": "posts/post-with-code/conditional.html",
    "title": "Conditional Mutation",
    "section": "",
    "text": "This was a quiz on the topic: Conditional Mutation. You can find the project here"
  },
  {
    "objectID": "posts/welcome/netflix.html",
    "href": "posts/welcome/netflix.html",
    "title": "Investigating the Netflix Movies",
    "section": "",
    "text": "This is the second project published in my portfolio. You can find it here"
  },
  {
    "objectID": "posts/Joining_data_with_pandas/join_pandas.html",
    "href": "posts/Joining_data_with_pandas/join_pandas.html",
    "title": "Joining data with Pandas",
    "section": "",
    "text": "The pandas package is a powerful tool for manipulating and transforming data in python. However, when working on an analytics, the data needed could be in multiple tables. Check here for some illustrations."
  },
  {
    "objectID": "CV.html",
    "href": "CV.html",
    "title": "My Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "posts/Project_5/project5.html",
    "href": "posts/Project_5/project5.html",
    "title": "CUSTOMER ANALYTICS: PREPARING DATA FOR MODELLING",
    "section": "",
    "text": "This project is about efficient data storage, so as to prepare the dataset fit for model creation. Check the project here"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Omotola Ayodele Lawal",
    "section": "Education",
    "text": "Education\nUniversity of Ibadan, Ibadan | Oyo State, Nigeria MB;BS | May 2015 - November 2022"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Omotola Ayodele Lawal",
    "section": "Experience",
    "text": "Experience\nNigerian Navy Reference Hospital, Ojo, Lagos, Nigeria | Medical Officer | February 2024 - Present\nFederal Medical Center, Owo | House Officer | January 2023 - January 2024"
  },
  {
    "objectID": "posts/Project_5/project5.html#section",
    "href": "posts/Project_5/project5.html#section",
    "title": "CUSTOMER ANALYTICS: PREPARING DATA FOR MODELLING",
    "section": "",
    "text": "The data used for this project is shown below and can be downloaded as a CSV.\n\n\n\n\nDownload as CSV"
  },
  {
    "objectID": "posts/Clean data/Clean_data.html",
    "href": "posts/Clean data/Clean_data.html",
    "title": "COURSE 15: CLEANING DATA IN PYTHON",
    "section": "",
    "text": "Dirty data can appear because of duplicate values, mis-spellings, data type parsing errors and legacy systems. Without ensuring that data is properly cleaned in the exploration and processing phase, we will surely compromise the insights and reports subsequently generated. As the old adage says, garbage in garbage out. Check here for details."
  },
  {
    "objectID": "Note/Date/date.html",
    "href": "Note/Date/date.html",
    "title": "COURSE 16: WORKING WITH DATES AND TIMES IN PYTHON",
    "section": "",
    "text": "You’ll probably never have a time machine, but how about a machine for analyzing time? As soon as time enters any analysis, things can get weird. It’s easy to get tripped up on day and month boundaries, time zones, daylight saving time, and all sorts of other things that can confuse the unprepared. If you’re going to do any kind of analysis involving time, you’ll want to use Python to sort it out. Working with data sets on hurricanes and bike trips, we’ll cover counting events, figuring out how much time has elapsed between events and plotting data over time. You’ll work in both standard Python and in Pandas, and we’ll touch on the dateutil library, the only timezone library endorsed by the official Python documentation. After this course, you’ll confidently handle date and time data in any format like a champion. Check here for details."
  },
  {
    "objectID": "Note.html",
    "href": "Note.html",
    "title": "Courses & Exercises",
    "section": "",
    "text": "Creating Choropleth maps with {ggplot2}\n\n\n\n\n\n\ncode\n\n\nnote\n\n\nData Reporting\n\n\nR\n\n\n\n\n\n\n\n\n\nFeb 18, 2025\n\n\nThe GRAPH Network\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Disease Maps with Labels in R\n\n\n\n\n\n\ncode\n\n\nnote\n\n\nData Reporting\n\n\nR\n\n\n\n\n\n\n\n\n\nFeb 18, 2025\n\n\nThe GRAPH Network\n\n\n\n\n\n\n\n\n\n\n\n\nPlot Labels with ggplot2\n\n\n\n\n\n\ncode\n\n\nnote\n\n\nData Reporting\n\n\nR\n\n\n\n\n\n\n\n\n\nJan 1, 2025\n\n\nThe GRAPH Network\n\n\n\n\n\n\n\n\n\n\n\n\nBar Charts & Pie Charts\n\n\n\n\n\n\ncode\n\n\nnote\n\n\nData Reporting\n\n\nR\n\n\n\n\n\n\n\n\n\nDec 29, 2024\n\n\nThe GRAPH Network\n\n\n\n\n\n\n\n\n\n\n\n\nDemographic Pyramids for Epidemiological Analysis\n\n\n\n\n\n\ncode\n\n\nnote\n\n\nData Reporting\n\n\nR\n\n\n\n\n\n\n\n\n\nDec 29, 2024\n\n\nThe GRAPH Network\n\n\n\n\n\n\n\n\n\n\n\n\nCOURSE 19 | SAMPLING AND POINT IN PYTHON\n\n\n\n\n\n\ncode\n\n\nnote\n\n\npython\n\n\n\n\n\n\n\n\n\nDec 26, 2024\n\n\nOmotola Ayodele Lawal\n\n\n\n\n\n\n\n\n\n\n\n\nLayers\n\n\n\n\n\n\ncode\n\n\nnote\n\n\nGeospatial\n\n\nR\n\n\n\n\n\n\n\n\n\nDec 22, 2024\n\n\nThe GRAPH Network\n\n\n\n\n\n\n\n\n\n\n\n\nBoundary Data\n\n\n\n\n\n\ncode\n\n\nnote\n\n\nGeospatial\n\n\nR\n\n\n\n\n\n\n\n\n\nDec 17, 2024\n\n\nThe GRAPH Network\n\n\n\n\n\n\n\n\n\n\n\n\nRead and Write Shapefiles\n\n\n\n\n\n\ncode\n\n\nnote\n\n\nGeospatial\n\n\nR\n\n\n\n\n\n\n\n\n\nDec 6, 2024\n\n\nThe GRAPH Network\n\n\n\n\n\n\n\n\n\n\n\n\nDensity Map\n\n\n\n\n\n\ncode\n\n\nnote\n\n\nGeospatial\n\n\nR\n\n\n\n\n\n\n\n\n\nDec 3, 2024\n\n\nThe GRAPH Network\n\n\n\n\n\n\n\n\n\n\n\n\nPhysical Features\n\n\n\n\n\n\ncode\n\n\nnote\n\n\nGeospatial\n\n\nR\n\n\n\n\n\n\n\n\n\nDec 2, 2024\n\n\nThe GRAPH Network\n\n\n\n\n\n\n\n\n\n\n\n\nThematic Maps\n\n\n\n\n\n\ncode\n\n\nnote\n\n\nGeospatial\n\n\nR\n\n\n\n\n\n\n\n\n\nDec 1, 2024\n\n\nThe GRAPH Network\n\n\n\n\n\n\n\n\n\n\n\n\nR for GIS\n\n\n\n\n\n\ncode\n\n\nnote\n\n\nGeospatial\n\n\nR\n\n\n\n\n\n\n\n\n\nNov 25, 2024\n\n\nThe GRAPH Network\n\n\n\n\n\n\n\n\n\n\n\n\nData Cleaning 2: Fixing Inconsistencies\n\n\n\n\n\n\ncode\n\n\nnote\n\n\nR\n\n\n\n\n\n\n\n\n\nNov 22, 2024\n\n\nThe GRAPH Network\n\n\n\n\n\n\n\n\n\n\n\n\nData Cleaning 1: Data Diagnostics\n\n\n\n\n\n\ncode\n\n\nnote\n\n\nR\n\n\n\n\n\n\n\n\n\nNov 21, 2024\n\n\nThe GRAPH Network\n\n\n\n\n\n\n\n\n\n\n\n\nCOURSE 18 | INTRODUCTION TO REGRESSION WITH STATSMODELS IN PYTHON\n\n\n\n\n\n\ncode\n\n\nnote\n\n\npython\n\n\n\n\n\n\n\n\n\nNov 21, 2024\n\n\nOmotola Ayodele Lawal\n\n\n\n\n\n\n\n\n\n\n\n\nLesson Notes: Intro to Functions and Conditionals\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nR\n\n\n\n\n\n\n\n\n\nNov 20, 2024\n\n\nThe GRAPH Network\n\n\n\n\n\n\n\n\n\n\n\n\nLoops, Across, and Conditionals\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nR\n\n\n\n\n\n\n\n\n\nNov 19, 2024\n\n\nThe GRAPH Network\n\n\n\n\n\n\n\n\n\n\n\n\nJoining 2: Mismatched Values, One-to-Many & Multi-Key Joins\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nR\n\n\n\n\n\n\n\n\n\nNov 18, 2024\n\n\nThe GRAPH Network\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to Joining Datasets\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nR\n\n\n\n\n\n\n\n\n\nNov 17, 2024\n\n\nThe GRAPH Network\n\n\n\n\n\n\n\n\n\n\n\n\nDates 2: Intervals, Components and Rounding\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nR\n\n\n\n\n\n\n\n\n\nNov 16, 2024\n\n\nThe GRAPH Network\n\n\n\n\n\n\n\n\n\n\n\n\nDates 1: Recognizing and Formatting Dates\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nR\n\n\n\n\n\n\n\n\n\nNov 13, 2024\n\n\nThe GRAPH Network\n\n\n\n\n\n\n\n\n\n\n\n\nFactors in R\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nR\n\n\n\n\n\n\n\n\n\nNov 12, 2024\n\n\nThe GRAPH Network\n\n\n\n\n\n\n\n\n\n\n\n\nWorking with Strings in R\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nR\n\n\n\n\n\n\n\n\n\nNov 11, 2024\n\n\nThe GRAPH Network Member\n\n\n\n\n\n\n\n\n\n\n\n\nFundamentals of Statistical Software & Analysis\n\n\n\n\n\n\nstatistic\n\n\npublic health\n\n\nR\n\n\n\n\n\n\n\n\n\nNov 10, 2024\n\n\nLawal’s note\n\n\n\n\n\n\n\n\n\n\n\n\nCOURSE 16: WORKING WITH DATES AND TIMES IN PYTHON\n\n\n\n\n\n\ncode\n\n\nnote\n\n\npython\n\n\n\n\n\n\n\n\n\nOct 17, 2024\n\n\nOmotola Ayodele Lawal\n\n\n\n\n\n\n\n\n\n\n\n\nCOURSE 15: CLEANING DATA IN PYTHON\n\n\n\n\n\n\ncode\n\n\nnote\n\n\npython\n\n\n\n\n\n\n\n\n\nOct 5, 2024\n\n\nOmotola Ayodele Lawal\n\n\n\n\n\n\n\n\n\n\n\n\nJoining data with Pandas\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\npython\n\n\n\n\n\n\n\n\n\nSep 4, 2024\n\n\nOmotola Ayodele Lawal\n\n\n\n\n\n\n\n\n\n\n\n\nConditional Mutation\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nr\n\n\n\n\n\n\n\n\n\nSep 2, 2024\n\n\nOmotola Ayodele Lawal\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Note/welcome/netflix.html",
    "href": "Note/welcome/netflix.html",
    "title": "Investigating the Netflix Movies",
    "section": "",
    "text": "This is the second project published in my portfolio. You can find it here"
  },
  {
    "objectID": "Note/conditional/conditional.html",
    "href": "Note/conditional/conditional.html",
    "title": "Conditional Mutation",
    "section": "",
    "text": "This was a quiz on the topic: Conditional Mutation. You can find the project here"
  },
  {
    "objectID": "Note/Joining_data_with_pandas/join_pandas.html",
    "href": "Note/Joining_data_with_pandas/join_pandas.html",
    "title": "Joining data with Pandas",
    "section": "",
    "text": "The pandas package is a powerful tool for manipulating and transforming data in python. However, when working on an analytics, the data needed could be in multiple tables. Check here for some illustrations."
  },
  {
    "objectID": "index.html#professional-development-training",
    "href": "index.html#professional-development-training",
    "title": "Omotola Ayodele Lawal",
    "section": "Professional Development Training",
    "text": "Professional Development Training\nSELF-PACED: Data Analysis & Statistics Sequence | The Global Research and Analysis for Public Health Network | June 2024 - Present\nAssociate Data Science Course in Python | DataCamp Inc | April 2024 - Present\nFundamentals of Statistical Software & Analysis (FoSSA) | University of Oxford Medical Sciences Division | August 2024 - November 2024"
  },
  {
    "objectID": "Note/Clean data/Clean_data.html",
    "href": "Note/Clean data/Clean_data.html",
    "title": "COURSE 15: CLEANING DATA IN PYTHON",
    "section": "",
    "text": "Dirty data can appear because of duplicate values, mis-spellings, data type parsing errors and legacy systems. Without ensuring that data is properly cleaned in the exploration and processing phase, we will surely compromise the insights and reports subsequently generated. As the old adage says, garbage in garbage out. Check here for details."
  },
  {
    "objectID": "posts/Netflix/netflix.html",
    "href": "posts/Netflix/netflix.html",
    "title": "Investigating the Netflix Movies",
    "section": "",
    "text": "This is the second project published in my portfolio. You can find it here"
  },
  {
    "objectID": "Note/Date/index.html",
    "href": "Note/Date/index.html",
    "title": "COURSE 16: WORKING WITH DATES AND TIMES IN PYTHON",
    "section": "",
    "text": "You’ll probably never have a time machine, but how about a machine for analyzing time? As soon as time enters any analysis, things can get weird. It’s easy to get tripped up on day and month boundaries, time zones, daylight saving time, and all sorts of other things that can confuse the unprepared. If you’re going to do any kind of analysis involving time, you’ll want to use Python to sort it out. Working with data sets on hurricanes and bike trips, we’ll cover counting events, figuring out how much time has elapsed between events and plotting data over time. You’ll work in both standard Python and in Pandas, and we’ll touch on the dateutil library, the only timezone library endorsed by the official Python documentation. After this course, you’ll confidently handle date and time data in any format like a champion. Check here for details."
  },
  {
    "objectID": "posts/Project_6/project6.html",
    "href": "posts/Project_6/project6.html",
    "title": "PROJECT | EXPLORING AIRBNB MARKET TRENDS",
    "section": "",
    "text": "Welcome to New York City, one of the most-visited cities in the world. There are many Airbnb listings in New York City to meet the high demand for temporary lodging for travelers, which can be anywhere between a few nights to many months. In this project, we will take a closer look at the New York Airbnb market by combining data from multiple file types like .csv, .tsv, and .xlsx. Check the project here"
  },
  {
    "objectID": "Note/FoSSa/fossa.html",
    "href": "Note/FoSSa/fossa.html",
    "title": "Fundamentals of Statistical Software & Analysis",
    "section": "",
    "text": "I completed the Fundamentals of Statistical Software and Analysis course, which comprises seven modules. The course is designed to teach students about statistical tests and software code used in medical sciences. Check this note for some details."
  },
  {
    "objectID": "Note/Strings/Strings.html",
    "href": "Note/Strings/Strings.html",
    "title": "Working with Strings in R",
    "section": "",
    "text": "Completing this course has made me proficient in string manipulation, a crucial skill for data scientists. Tasks such as cleaning messy data and formatting outputs rely heavily on the ability to parse, combine, and modify character strings. This lesson focuses on techniques for working with strings in R, using functions from the {stringr} package in the tidyverse. You can refer here for further review"
  },
  {
    "objectID": "Note/Factors/Factors.html",
    "href": "Note/Factors/Factors.html",
    "title": "Factors in R",
    "section": "",
    "text": "Factors are an important data class for representing and working with categorical variables in R.\nCompleting the course was crucial in helping me to have a strong foundational skills on how to create factors and how to manipulate them with functions from the forcats package, a part of the tidyverse. You can refer here for further review"
  },
  {
    "objectID": "Note/date_1/date_1.html",
    "href": "Note/date_1/date_1.html",
    "title": "Dates 1: Recognizing and Formatting Dates",
    "section": "",
    "text": "Manipulating dates is a crucial skill in health data analysis, as date-related data, from patient admission dates to vaccination schedules, plays a vital role in epidemiological studies. To strengthen this skill, I completed part 1 of the course, which covered how R stores and displays dates and provided techniques for effectively manipulating, parsing, and formatting them. You can refer here for further review"
  },
  {
    "objectID": "Note/date_2/date_2.html",
    "href": "Note/date_2/date_2.html",
    "title": "Dates 2: Intervals, Components and Rounding",
    "section": "",
    "text": "Building on the knowledge gained in Part 1 of the course on date analysis in R, this lesson helped me strengthen my ability to perform basic date analyses. I learned techniques such as calculating intervals between dates and creating time series graphs. These skills are essential for health data professionals, as they form the foundation for understanding temporal patterns, including disease progression over time and fluctuations in population health metrics across various periods. You can refer here for further review"
  },
  {
    "objectID": "Note/join/join.html",
    "href": "Note/join/join.html",
    "title": "Intro to Joining Datasets",
    "section": "",
    "text": "Joining datasets is an essential skill in health data analysis, enabling the integration of information from multiple sources for more comprehensive and insightful analyses. Completing Part 1 of this course has equipped me with the knowledge to apply various joining techniques using R’s dplyr package. Check here for further review"
  },
  {
    "objectID": "Note/join_2/join_2.html",
    "href": "Note/join_2/join_2.html",
    "title": "Joining 2: Mismatched Values, One-to-Many & Multi-Key Joins",
    "section": "",
    "text": "Building on the knowledge gained in Part 1 of the course on joining datasets in R, this lesson enhanced my ability to work with messier and more complex datasets. I learned how to identify mismatched values between data frames, perform joins using one-to-many matches, and execute joins based on multiple key columns. For further review, check here."
  },
  {
    "objectID": "Note/loop/loop.html",
    "href": "Note/loop/loop.html",
    "title": "Loops, Across, and Conditionals",
    "section": "",
    "text": "Repetition is a fundamental concept in programming, often essential for automating tasks. In R, a for loop provides an efficient way to repeat a task multiple times, saving both time and effort. Through the course, I have gained the ability to:\n\nExplain the syntax and structure of a basic for loop in R.\nUtilize index variables to iterate through multiple vectors simultaneously within a loop.\nIncorporate if/else conditional statements to add decision-making within loops.\nStore loop results in vectors and lists for further analysis.\nApply loops to real-world tasks such as analyzing multiple datasets and generating multiple plots.\nDebug loops effectively by isolating and testing individual iterations.\n\nThis knowledge equips me to handle repetitive tasks in R with greater precision and efficiency.\nFor further review, check here."
  },
  {
    "objectID": "Note/functions/functions.html",
    "href": "Note/functions/functions.html",
    "title": "Lesson Notes: Intro to Functions and Conditionals",
    "section": "",
    "text": "The R language revolves around two fundamental components: objects and functions. Objects are the data structures used to store information, while functions are the tools used to manipulate these objects. As paraphrased from John Chambers, one of R’s originators, “everything that exists in R is an object, and everything that happens is a function.”\nMastering the creation and use of functions enables automation of repetitive tasks, enhances efficiency, and reduces coding errors.\nThrough this lesson, I have gained the ability to:\n\nCreate and use custom functions in R.\nDesign function arguments and define default values.\nIncorporate conditional logic, such as if, else if, and else, within functions.\nValidate function arguments to prevent errors.\nManage function scope and understand the differences between local and global variables.\nWork with vectorized data within functions.\nOrganize and store custom functions for future use.\n\nFor further review, check here."
  },
  {
    "objectID": "Note/data_clean1/data_clean1.html",
    "href": "Note/data_clean1/data_clean1.html",
    "title": "Data Cleaning 1: Data Diagnostics",
    "section": "",
    "text": "Data cleaning is the process of converting raw, “messy data” into reliable, analyzable information. This involves identifying and addressing inaccurate, incomplete, or improbable data points, resolving inconsistencies or errors, and renaming variables to make them clearer and easier to work with. While data cleaning can often be tedious and time-consuming, it is a crucial step in the data analysis process. Investing time in cleaning your data early on significantly enhances the quality of your analyses and simplifies the analytical workflow.\nAfter completing this lesson, I am now able to diagnose dataset issues requiring cleaning using functions such as:\n\nvisdat::vis_dat()\ninspectdf::inspect_cat()\ninspectdf::inspect_num()\ngtsummary::tbl_summary()\n\nCheck here for details."
  },
  {
    "objectID": "Note/data_clean2/data_clean2.html",
    "href": "Note/data_clean2/data_clean2.html",
    "title": "Data Cleaning 2: Fixing Inconsistencies",
    "section": "",
    "text": "Building on the knowledge from the previous lesson , where I explored various functions for diagnosing data issues, completing this lesson has enabled me to:\n\nUnderstand and apply techniques to clean column names, both automatically and manually.\nEffectively remove duplicate entries from datasets.\nCorrect and standardize string values in data.\nConvert data types to suit specific requirements.\n\nCheck here for details."
  },
  {
    "objectID": "posts/Project_7/project7.html",
    "href": "posts/Project_7/project7.html",
    "title": "PROJECT | MODELING CAR INSURANCE CLAIMS OUTCOME",
    "section": "",
    "text": "Insurance companies invest significant resources into optimizing pricing strategies and accurately predicting the likelihood of customer claims. In many countries, car insurance is legally required for driving on public roads, making the market vast and competitive.\nThis project focused on building a predictive model to determine whether a customer is likely to file a claim during the policy period. The approach involved identifying the single feature that yielded the highest model accuracy, providing valuable insights for improved decision-making.\nCheck the project here"
  },
  {
    "objectID": "Note/Regression_1/Regression_1.html",
    "href": "Note/Regression_1/Regression_1.html",
    "title": "COURSE 18 | INTRODUCTION TO REGRESSION WITH STATSMODELS IN PYTHON",
    "section": "",
    "text": "Completing the course on Introduction to Regression with statsmodels in Python, I gained a comprehensive understanding of regression analysis and its application in Python. Here’s a summary of what I learned:\n\nFundamentals of Regression: I learned the basics of regression analysis, including the difference between linear and logistic regression models.\nFitting Simple Linear Regression Models: I explored how to fit linear regression models with both numeric and categorical explanatory variables and how to interpret model coefficients to describe relationships between the response and explanatory variables.\nMaking Predictions: I learned how to use linear regression models to make predictions on various datasets, providing actionable insights from the model’s outputs.\nRegression to the Mean: I gained an understanding of the concept of “regression to the mean” and its implications in statistical analysis.\nTransforming Variables: I explored techniques to transform variables in a dataset to improve model performance and interpretability.\nModel Assessment: I learned how to evaluate the fit of a regression model by asking specific questions and using diagnostic techniques to assess its accuracy.\nModel Diagnostics: I discovered how to quantify the quality of model fits, diagnose problems with visualizations, and understand the influence of each observation, including its leverage, on the final model.\nFitting Logistic Regression Models: I learned how to fit logistic regression models, focusing on real-world applications. For example, I predicted the likelihood of a customer closing their bank account, interpreted probabilities of success, and understood odds ratios.\nModel Performance Evaluation: I also learned how to assess model performance using confusion matrices, which help quantify the effectiveness of logistic regression predictions.\n\nCheck here for details."
  },
  {
    "objectID": "posts/Project_8/project8.html",
    "href": "posts/Project_8/project8.html",
    "title": "PROJECT | BUILDING A CALORIE INTAKE CALCULATOR",
    "section": "",
    "text": "This project aimed to enhance the app of a Health and Leisure company by adding a new feature: a calorie and nutrition calculator. The tool allows users to input different foods and calculates their total calories, sugars, fats, and other nutritional values.\nCheck the project here."
  },
  {
    "objectID": "Note/R_GIS/R_GIS.html",
    "href": "Note/R_GIS/R_GIS.html",
    "title": "R for GIS",
    "section": "",
    "text": "What is Geospatial Analysis?\nGeospatial analysis involves collecting, analyzing, and interpreting data tied to geographic locations and the characteristics of physical features or phenomena on Earth’s surface. It leverages spatial information—such as coordinates, maps, or geospatial data layers—to uncover patterns, relationships, and insights that may not be apparent in non-spatial data.\nThis approach is particularly valuable in fields like epidemiology, where it helps identify hotspots and high-risk areas for the spread of communicable diseases.\n\n\nWhy Use R for Geospatial Work?\nR is a powerful tool for geospatial analysis, offering several advantages:\n\nReproducibility: R allows you to automate workflows and share reproducible code for consistent results.\nReporting: With packages like rmarkdown, R makes it easy to integrate analysis, visualization, and reporting in a seamless document.\nRich Ecosystem: R provides a vast collection of geospatial packages, such as sf, raster, and leaflet, to handle data wrangling, visualization, and analysis.\nConvenience: R’s syntax and tools simplify complex geospatial tasks, from mapping to statistical modeling.\nIntegrated Workflow: R enables users to combine geospatial visualization and statistical analysis in a single script, streamlining the analytical process.\n\nBy leveraging R’s capabilities, geospatial analysts can efficiently handle complex spatial datasets and deliver actionable insights.\nCheck here for details."
  },
  {
    "objectID": "Note/Thematic_map/Thematic_map.html",
    "href": "Note/Thematic_map/Thematic_map.html",
    "title": "Thematic Maps",
    "section": "",
    "text": "After completing this course, I have gained the following skills:\n\nUnderstanding Thematic Maps:\n\n\nI can identify and explain two key types of thematic maps commonly used in epidemiology:\n\nChoropleth Maps: Used to represent spatial data variations based on areas.\nDot Maps: Used to show the distribution of phenomena using dots or symbols.\n\n\n\nCreating Thematic Maps:\n\n\nI can effectively create thematic maps in R using the {ggplot2} package and the geom_sf() function, leveraging its flexibility to visualize geospatial data.\n\n\nRelating Maps to Geometry Types:\n\n\nI have learned how each type of thematic map aligns with specific geometry types, enhancing the accuracy and relevance of data visualization.\n\nFor a detailed walkthrough and examples, please visit this site."
  },
  {
    "objectID": "Note/Physical_features/Physical_feature.html",
    "href": "Note/Physical_features/Physical_feature.html",
    "title": "Physical Features",
    "section": "",
    "text": "Understanding geographic context is essential for spatial data, as it helps in locating events in relation to environmental features like streets and landmarks.\nThrough this learning journey, I have gained the following skills:\n\nAdding physical features to maps to enhance geographic context.\nPlotting multiple layers on maps to complement thematic visualizations.\nRelating physical features to their respective geometry types for accurate representation.\n\nFor more insights, check it out on this site."
  },
  {
    "objectID": "Note/Density_map/Density_map.html",
    "href": "Note/Density_map/Density_map.html",
    "title": "Density Map",
    "section": "",
    "text": "A density map is a type of thematic map that uses colors to represent the intensity of a value. Unlike traditional maps, it doesn’t rely on predefined regions or geopolitical boundaries but highlights ‘hot spots’—areas with high density or concentration of points.\nThrough this course, I gained the skills to:\n\nBuild density maps commonly used by epidemiologists to visualize overlapping geospatial data.\nEnhance thematic maps with basemaps (Google Maps-like backgrounds) using the annotation_map_tile() function from the {ggspatial} package.\n\nCheck out this site for a beginner-friendly overview and examples."
  },
  {
    "objectID": "Note/read_sf/read_sf.html",
    "href": "Note/read_sf/read_sf.html",
    "title": "Read and Write Shapefiles",
    "section": "",
    "text": "Completing this course equipped me with valuable skills to:\n\nRead spatial data from Shapefiles using the read_sf() function from the {sf} package.\nUnderstand the components of sf objects and Shapefiles.\nWrite spatial data into Shapefiles using write_sf().\n\nExplore this site for a beginner-friendly overview and examples."
  },
  {
    "objectID": "Note/boundary_data/boundary_data.html",
    "href": "Note/boundary_data/boundary_data.html",
    "title": "Boundary Data",
    "section": "",
    "text": "Country borders and boundaries serve multiple purposes. They can be used as a background in thematic maps, as delimiters for other spatial data, or to identify spread patterns and calculate the intersection between spatial objects (e.g., points within polygons).\nAccessing this type of data may produce different outputs, such as low- or high-resolution borders or varying administrative levels. The choice of resolution or administrative detail depends on your specific requirements.\nIn this lesson, I learned how to access:\n\nLow-resolution boundaries of continents and countries using the {rnaturalearth} package.\nHigh-resolution boundaries of continents and countries with the {rgeoboundaries} package.\nAdditional geographic data using the {geodata} package.\n\nExplore this site for a beginner-friendly overview and examples."
  },
  {
    "objectID": "Note/layers/layers.html",
    "href": "Note/layers/layers.html",
    "title": "Layers",
    "section": "",
    "text": "In this lesson, I learned to enhance ggplot maps by using the {ggspatial} package to add north arrows and scale annotations, and the {ggsflabel} package to incorporate text and labels effectively.\nFor more insights, check it out on this site."
  },
  {
    "objectID": "Note/Sampling/Sampling.html",
    "href": "Note/Sampling/Sampling.html",
    "title": "COURSE 19 | SAMPLING AND POINT IN PYTHON",
    "section": "",
    "text": "Completing the course on Sampling and Point Estimation in Python has provided me with a thorough understanding of key concepts and techniques in statistical sampling. Below is a summary of my learning journey:\n\nIntroduction to Sampling: I explored what sampling is and why it is such a powerful statistical tool. I also delved into the challenges posed by convenience sampling and the differences between true randomness and pseudo-randomness in data generation.\nHands-On Sampling Methods: Through practical exercises, I applied four core random sampling techniques in Python:\n\n\nSimple Sampling\nSystematic Sampling\nStratified Sampling\nCluster Sampling\n\n\nEvaluating Sample Accuracy: I learned to quantify the accuracy of sample statistics by calculating relative errors. Additionally, I gained insights into measuring variation in sample estimates by generating and analyzing sampling distributions.\nResampling and Bootstrap Techniques: Resampling methods were introduced as tools for estimating variation in unknown populations. I practiced bootstrapping techniques to generate bootstrap distributions and learned to distinguish them from sampling distributions.\nConfidence Intervals: Finally, I formalized the concept of confidence intervals to assess the reliability of statistical estimates. This included understanding the importance of values within one standard deviation of the mean and their role in describing distributions.\n\nThis comprehensive course equipped me with practical skills and theoretical insights into sampling and statistical analysis in Python, strengthening my ability to draw meaningful conclusions from data.\nCheck here for details."
  },
  {
    "objectID": "Note/demographics/Physical_feature.html",
    "href": "Note/demographics/Physical_feature.html",
    "title": "Demographic Pyramids for Epidemiological Analysis",
    "section": "",
    "text": "A demographic pyramid, also known as a population or age-sex pyramid, is a powerful tool for visualizing population distribution by age and sex.\nThis tool becomes particularly valuable when analyzing disease patterns across these demographic variables.\nThrough this learning experience, I have gained the following skills and insights:\n\nUnderstanding the Value of Demographic Pyramids:\n\n\nRecognized their importance in communicating age- and sex-specific patterns of disease distribution.\nConceptualized the demographic pyramid as a modified stacked bar plot.\n\n\nData Preparation\n\n\nLearned to summarize and structure data for plotting using {dplyr} functions.\n\n\nPlotting with {ggplot2}\n\n\nCreated demographic pyramids with geom_col(), displaying total counts or percentages on the x-axis.\n\n\nCustomization\n\n\nEnhanced plots by adjusting the color scheme, labels, and axes for clear communication and visual appeal.\n\nThis comprehensive learning journey has equipped me with the skills to effectively use demographic pyramids for epidemiological analysis.\nFor more insights, check it out on this site."
  },
  {
    "objectID": "Note/Bar_chart/Physical_feature.html",
    "href": "Note/Bar_chart/Physical_feature.html",
    "title": "Physical Features",
    "section": "",
    "text": "Understanding geographic context is essential for spatial data, as it helps in locating events in relation to environmental features like streets and landmarks.\nThrough this learning journey, I have gained the following skills:\n\nAdding physical features to maps to enhance geographic context.\nPlotting multiple layers on maps to complement thematic visualizations.\nRelating physical features to their respective geometry types for accurate representation.\n\nFor more insights, check it out on this site."
  },
  {
    "objectID": "Note/plot_label/Physical_feature.html",
    "href": "Note/plot_label/Physical_feature.html",
    "title": "Physical Features",
    "section": "",
    "text": "Understanding geographic context is essential for spatial data, as it helps in locating events in relation to environmental features like streets and landmarks.\nThrough this learning journey, I have gained the following skills:\n\nAdding physical features to maps to enhance geographic context.\nPlotting multiple layers on maps to complement thematic visualizations.\nRelating physical features to their respective geometry types for accurate representation.\n\nFor more insights, check it out on this site."
  },
  {
    "objectID": "Note/demographics/demographics.html",
    "href": "Note/demographics/demographics.html",
    "title": "Demographic Pyramids for Epidemiological Analysis",
    "section": "",
    "text": "A demographic pyramid, also known as a population or age-sex pyramid, is a powerful tool for visualizing population distribution by age and sex.\nThis tool becomes particularly valuable when analyzing disease patterns across these demographic variables.\nThrough this learning experience, I have gained the following skills and insights:\n\nUnderstanding the Value of Demographic Pyramids:\n\n\nRecognized their importance in communicating age- and sex-specific patterns of disease distribution.\nConceptualized the demographic pyramid as a modified stacked bar plot.\n\n\nData Preparation\n\n\nLearned to summarize and structure data for plotting using {dplyr} functions.\n\n\nPlotting with {ggplot2}\n\n\nCreated demographic pyramids with geom_col(), displaying total counts or percentages on the x-axis.\n\n\nCustomization\n\n\nEnhanced plots by adjusting the color scheme, labels, and axes for clear communication and visual appeal.\n\nThis comprehensive learning journey has equipped me with the skills to effectively use demographic pyramids for epidemiological analysis.\nFor more insights, check it out on this site."
  },
  {
    "objectID": "Note/Bar_chart/Bar_chart.html",
    "href": "Note/Bar_chart/Bar_chart.html",
    "title": "Bar Charts & Pie Charts",
    "section": "",
    "text": "During this learning journey, I have developed a clear understanding of key concepts and skills for data visualization:\n\nComparisons vs. Compositions\n\n\nDifferentiated between visualizing comparisons (showing differences between categories) and visualizing compositions (showing parts of a whole).\nLearned to identify appropriate chart types for these two types of analysis.\n\n\nBar Charts\n\n\nCreated and customized bar charts for comparing categorical data using geom_col(), geom_errorbar(), and position adjustments.\n\n\nPie Charts\n\n\nDesigned and customized pie charts to visualize compositions using coord_polar() with geom_col().\n\nThese skills have enhanced my ability to present data effectively for comparison and composition analysis using {ggplot2}.\nFor more insights, check it out on this site."
  },
  {
    "objectID": "Note/plot_label/plot_label.html",
    "href": "Note/plot_label/plot_label.html",
    "title": "Plot Labels with ggplot2",
    "section": "",
    "text": "Bar plots are among the most versatile chart types, with numerous variations for visualizing data. In a previous lesson, I learned how to create bar plots and their circular counterparts using {ggplot2}. Building on that foundation, this lesson focused on enhancing visualizations through effective labeling and data transformation.\nKey takeaways from this lesson include:\n\nUsing Text Geoms for Labeling\n\n\nApplied geom_text() for simple labels.\nUsed geom_label() for more emphasized labels.\n\n\nData Preparation\n\n\nTransformed and summarized data into the appropriate formats for various chart types.\n\n\nLabel Placement on Bar Plots\n\n\nPositioned labels accurately on stacked, dodged, and percent-stacked bar plots.\n\n\nLabel Placement on Circular Charts\n\n\nAdjusted label placement effectively on pie charts and donut plots.\n\nThis lesson significantly improved my skills in creating and customizing labeled bar and circular plots, ensuring clear and effective data communication.\nFor more insights, check it out on this site."
  },
  {
    "objectID": "Note/Disease_Mapping/Disease_mapping.html",
    "href": "Note/Disease_Mapping/Disease_mapping.html",
    "title": "Creating Choropleth maps with {ggplot2}",
    "section": "",
    "text": "A choropleth map is a powerful thematic map where geographic regions are shaded or patterned based on the value of a specific variable. These maps are widely used in epidemiology, helping to visualize indicators such as disease prevalence or mortality rates across different regions. By displaying spatial patterns effectively, choropleth maps enhance data-driven decision-making.\n\nKey Skills Acquired\nThrough this course, I have gained expertise in:\n\nChoropleth Maps with `{ggplot2}\n\n\nMaster the ggplot() and geom_sf() functions for creating visually appealing maps.\nLearn how to customize map aesthetics, including colors, labels, and legends.\n\n\nData Matching with Geographic Polygons\n\n\nAcquiring and integrating boundary data with disease-related datasets.\nMerging spatial and statistical data at different administrative levels.\n\n\nColor Scaling Techniques\n\n\nImplement color scales for both continuous and discrete data types.\nChoose appropriate color palettes to effectively communicate data trends and patterns.\n\n\nFaceting for Map Visualization\n\n\nUse facet_wrap() and facet_grid() to create small multiple maps.\nCompare multiple variables or time periods side by side for deeper insights.\n\nBy mastering these techniques, I can now create insightful, data-driven maps that reveal meaningful geographic trends.\nFor a detailed walkthrough and examples, please visit this site."
  },
  {
    "objectID": "Note/Labelling_map/Labelling_map.html",
    "href": "Note/Labelling_map/Labelling_map.html",
    "title": "Enhancing Disease Maps with Labels in R",
    "section": "",
    "text": "Maps are powerful storytelling tools in geospatial data visualization. However, a map without clear annotations and labels is like a book without titles or chapter headings—while the story exists, it becomes much harder to understand, interpret, and appreciate.\nThrough this lesson, I gained a deeper understanding of how proper annotation transforms a simple visualization into an informative guide. Precise labeling helps highlight areas of interest, making it easier for viewers to grasp complex spatial data and its narrative.\n\nKey Skills Acquired\nAfter completing this course, I was able to:\n\nEnhance Choropleth Maps – Integrate continuous data indicators for better granularity.\nOverlay State Names Clearly – Ensure readability without cluttering the visualization.\nCombine Labels with Data Trends – Seamlessly integrate state names with increasing rates while maintaining legibility.\nHighlight Key Regions – Apply techniques to emphasize specific areas while preserving overall map context.\nOptimize Point Placement – Strategically position labels to improve clarity in geospatial visualizations.\n\nBy mastering these techniques, I can now create detailed, insightful, and user-friendly maps that effectively communicate spatial data.\nFor a step-by-step guide and examples, visit this site."
  }
]